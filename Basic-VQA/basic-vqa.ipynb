{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from easy_vqa import get_train_questions, get_test_questions, get_answers, get_train_image_paths, get_test_image_paths\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNN\n",
    "im_input = Input(shape=(64, 64, 3))\n",
    "x1 = Conv2D(8, 3, padding='same')(im_input)\n",
    "x1 = MaxPooling2D()(x1)\n",
    "x1 = Conv2D(16, 3, padding='same')(x1)\n",
    "x1 = MaxPooling2D()(x1)\n",
    "x1 = Flatten()(x1)\n",
    "# Add a final fully-connected layer after the CNN for good measure\n",
    "x1 = Dense(32, activation='tanh')(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Read questions\n",
    "# train_qs and test_qs are just arrays of question strings\n",
    "# (we'll use the other variables later)\n",
    "train_qs, train_answers, train_image_ids = get_train_questions()\n",
    "test_qs, test_answers, test_image_ids = get_test_questions()\n",
    "\n",
    "all_answers = get_answers()\n",
    "num_answers = len(all_answers)\n",
    "\n",
    "\n",
    "# Fit tokenizer on the training questions\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_qs)\n",
    "\n",
    "# Convert questions to BOW\n",
    "train_X_seqs = tokenizer.texts_to_matrix(train_qs)\n",
    "test_X_seqs = tokenizer.texts_to_matrix(test_qs)\n",
    "\n",
    "# Example BOW:\n",
    "# [0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "print(train_X_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add one because the Keras Tokenizer reserves index 0 and never uses it.\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# The question network\n",
    "q_input = Input(shape=(vocab_size,))\n",
    "x2 = Dense(32, activation='tanh')(q_input)\n",
    "x2 = Dense(32, activation='tanh')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply\n",
    "out = Multiply()([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(32, activation='tanh')(out)\n",
    "# num_answers will be defined below\n",
    "out = Dense(num_answers, activation='softmax')(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[im_input, q_input], outputs=out)\n",
    "model.compile(\n",
    "  Adam(lr=2e-4), # somewhat arbitrarily chosen\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_proccess_image(image_path):\n",
    "  # Load image, then scale and shift pixel values to [-0.5, 0.5]\n",
    "  im = img_to_array(load_img(image_path))\n",
    "  return im / 255 - 0.5\n",
    "\n",
    "def read_images(paths):\n",
    "  # paths is a dict mapping image ID to image path\n",
    "  # Returns a dict mapping image ID to the processed image\n",
    "  ims = {}\n",
    "  for image_id, image_path in paths.items():\n",
    "    ims[image_id] = load_and_proccess_image(image_path)\n",
    "  return ims\n",
    "\n",
    "train_ims = read_images(get_train_image_paths())\n",
    "test_ims = read_images(get_test_image_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model input images\n",
    "train_X_ims = [train_ims[id] for id in train_image_ids]\n",
    "test_X_ims = [test_ims[id] for id in test_image_ids]\n",
    "\n",
    "train_X_ims = np.array(train_X_ims)\n",
    "test_X_ims = np.array(test_X_ims)\n",
    "\n",
    "# Create model outputs\n",
    "train_answer_indices = [all_answers.index(a) for a in train_answers]\n",
    "test_answer_indices = [all_answers.index(a) for a in test_answers]\n",
    "train_Y = to_categorical(train_answer_indices)\n",
    "test_Y = to_categorical(test_answer_indices)\n",
    "\n",
    "train_Y = np.array(train_Y)\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model!\n",
    "model.fit(\n",
    "  \n",
    "  [train_X_ims, train_X_seqs],\n",
    "  train_Y,\n",
    "  validation_data=([test_X_ims, test_X_seqs], test_Y),\n",
    "  shuffle=True,\n",
    "  epochs=100,\n",
    "  callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}